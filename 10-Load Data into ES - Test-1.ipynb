{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Data into ES - Test-1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "elasticsearch.client.indices.IndicesClient"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- Create an ES Client -------------------------\n",
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch(\n",
    "    \"localhost:9200\",\n",
    "    http_auth=[\"elastic\", \"changeme\"], \n",
    ") \n",
    "# ------------------------- Create an ES Index Client -------------------------\n",
    "from elasticsearch.client import IndicesClient\n",
    "es_index_client = IndicesClient(es_client)\n",
    "type(es_index_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/3qy8wy6s2571t48bzrjk5vl80000gn/T/ipykernel_36071/210381053.py:64: DeprecationWarning: The 'body' parameter is deprecated for the 'create' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  es_index_client.create(index=\"esg_report_1\", body=configurations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'esg_report_1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- Define the Settings & Mappings - Ver.1 -------------------------\n",
    "configurations = {\n",
    "  \"settings\": {\n",
    "      \"index\": {\n",
    "          \"number_of_replicas\": 1},\n",
    "      \"analysis\": {\n",
    "          \"filter\": {\n",
    "              \"ngram_filter\": {\n",
    "                \"type\": \"edge_ngram\",\n",
    "                \"min_gram\": 2,\n",
    "                \"max_gram\": 50}\n",
    "          },\n",
    "          \"analyzer\": {\n",
    "              \"ngram_analyzer\": {\n",
    "                  \"type\": \"custom\",\n",
    "                  \"tokenizer\": \"standard\",\n",
    "                  \"filter\": [\n",
    "                    \"lowercase\",\n",
    "                    \"ngram_filter\"]\n",
    "              }\n",
    "          }\n",
    "      }\n",
    "  },\n",
    "  \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\n",
    "                \"type\": \"long\"},\n",
    "            \"label\": {\n",
    "                \"type\": \"long\"},\n",
    "            \"company\": {\n",
    "                \"type\": \"text\"},\n",
    "            \"industry\": {\n",
    "                \"type\": \"text\"},\n",
    "            \"country\": {\n",
    "                \"type\": \"text\"},\n",
    "            \"content\": {\n",
    "                \"type\": \"nested\",\n",
    "                \"properties\": {\n",
    "                    \"page\": {\n",
    "                        \"type\": \"long\"},\n",
    "                    \"priority\": {\n",
    "                        \"type\": \"float\"},\n",
    "                    \"sentence\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"analyzer\": \"standard\",\n",
    "                        \"fields\": {\n",
    "                            \"keyword\": {\n",
    "                                \"type\": \"keyword\"},\n",
    "                            \"ngrams\": {\n",
    "                                \"type\": \"text\",\n",
    "                                \"analyzer\": \"ngram_analyzer\"}\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# ------------------------- Create an ES Index -------------------------\n",
    "es_index_client.create(index=\"esg_report_1\", body=configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index with new configurations\n",
    "# in Kibana:    DELETE esg_report_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of positive CSV files: 196\n",
      "Type of pos_file_list items: <class 'str'>\n",
      "Total number of negative CSV files: 177\n",
      "Type of pos_file_list items: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# List all trimmed CSV files from the Crawler\n",
    "pos_file_list = os.listdir(\"Crawler & Processing/2.Develop - Crawler Folder/preprocessed/trimmed/pos\")\n",
    "pos_file_list.sort()\n",
    "print(\"Total number of positive CSV files:\", len(pos_file_list))\n",
    "print(\"Type of pos_file_list items:\", type(pos_file_list[0]))\n",
    "# print(\"Show the pos_file_list:\", pos_file_list)\n",
    "\n",
    "neg_file_list = os.listdir(\"Crawler & Processing/2.Develop - Crawler Folder/preprocessed/trimmed/neg\")\n",
    "neg_file_list.sort()\n",
    "print(\"Total number of negative CSV files:\", len(neg_file_list))\n",
    "print(\"Type of pos_file_list items:\", type(neg_file_list[0]))\n",
    "# print(\"Show the pos_file_list:\", neg_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>company</th>\n",
       "      <th>industry</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Aurubis AG</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Maire Tecnimont SpA</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2019-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Faber-Castell AG</td>\n",
       "      <td>Consumer discretionary</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-02-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id label              company                industry  country        date\n",
       "0  11     1           Aurubis AG               Materials  Germany  2020-06-10\n",
       "1   8     1  Maire Tecnimont SpA             Industrials    Italy  2019-12-04\n",
       "2   9     1     Faber-Castell AG  Consumer discretionary  Germany  2020-02-12"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### For Positive reports only\n",
    "column_names = [\"id\", \"label\", \"company\", \"industry\", \"country\", \"date\"]\n",
    "\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for file in file_list:\n",
    "    \n",
    "    # Get the file name without \".csv\"\n",
    "    pdf_ID = int(file.split(\".\")[0])\n",
    "    # Positive label defined as 1\n",
    "    pos_label = 1\n",
    "    # Get the company info\n",
    "    matched_row = com_details[com_details[\"Unique ID\"]==pdf_ID].iloc[0] # Find matched row and get the first row\n",
    "    company_name = matched_row[\"Issuer - subsidiary\"]\n",
    "    industry_name = matched_row[\"Issuer industry\"]\n",
    "    country_name = matched_row[\"Country of risk\"]\n",
    "    date_str = str(matched_row[\"Date\"]).split(\" \")[0]\n",
    "    \n",
    "    df = df.append({\"id\": pdf_ID, \n",
    "                    \"label\": pos_label, \n",
    "                    \"company\": company_name, \n",
    "                    \"industry\": industry_name, \n",
    "                    \"country\": country_name,\n",
    "                    \"date\": date_str}, ignore_index=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in file_list:\n",
    "    print(fileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "page\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "page\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "26\n",
      "26\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "columns = [\"page\", \"priority\", \"content\"]\n",
    "index_name = \"esg_report_1\"\n",
    "\n",
    "for fileName in file_list:\n",
    "    action_list = []  \n",
    "    \n",
    "    action = {\"index\": {\"_index\": index_name, \"_id\": int(row[\"id\"])}}  \n",
    "    \n",
    "    with open(\"Crawler & Processing/2.Develop - Crawler Folder/preprocessed/trimmed/pos_test/\" + fileName, \"r\") as f:\n",
    "        csv_file = csv.DictReader(f, fieldnames=columns, delimiter=\",\", quotechar='\"') \n",
    "        \n",
    "        next(csv_file)  \n",
    "\n",
    "        \n",
    "        \n",
    "        for row in csv_file:\n",
    "            \n",
    "            doc = {\n",
    "                    \"id\": int(row[\"id\"]), \n",
    "                    \"name\": row[\"name\"],\n",
    "                    \"price\": float(row[\"price\"]),\n",
    "                    \"brand\": row[\"brand\"],\n",
    "                    \"attributes\": [\n",
    "                                    {\"attribute_name\": \"cpu\", \"attribute_value\": row[\"cpu\"]},\n",
    "                                    {\"attribute_name\": \"memory\", \"attribute_value\": row[\"memory\"]},\n",
    "                                    {\"attribute_name\": \"storage\", \"attribute_value\": row[\"storage\"],},\n",
    "                                    ],\n",
    "                    }\n",
    "            action_list.append(json.dumps(action))  \n",
    "            action_list.append(json.dumps(doc)) \n",
    "            print(row[\"page\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numFiles:\n",
    "    file = open(os.path.join(pathName, i), \"rU\")\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for row in reader:\n",
    "        for column in row:\n",
    "            print(column)\n",
    "            if column==\"SPECIFIC VALUE\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Read Data and Bulk Process Docs -------------------------\n",
    "colunms = [\"id\", \"name\", \"price\", \"brand\", \"cpu\", \"memory\", \"storage\"]\n",
    "index_name = \"laptops-demo\"\n",
    "\n",
    "with open(\"csv_files/laptops_demo.csv\", \"r\") as f:\n",
    "    reader = csv.DictReader(f, fieldnames=colunms, delimiter=\",\", quotechar='\"') \n",
    "    \n",
    "    next(reader)  \n",
    "\n",
    "    action_list = []  \n",
    "    \n",
    "    for row in reader:\n",
    "        action = {\"index\": {\"_index\": index_name, \"_id\": int(row[\"id\"])}}  \n",
    "        doc = {\n",
    "                \"id\": int(row[\"id\"]), \n",
    "                \"name\": row[\"name\"],\n",
    "                \"price\": float(row[\"price\"]),\n",
    "                \"brand\": row[\"brand\"],\n",
    "                \"attributes\": [\n",
    "                                {\"attribute_name\": \"cpu\", \"attribute_value\": row[\"cpu\"]},\n",
    "                                {\"attribute_name\": \"memory\", \"attribute_value\": row[\"memory\"]},\n",
    "                                {\"attribute_name\": \"storage\", \"attribute_value\": row[\"storage\"],},\n",
    "                                ],\n",
    "                }\n",
    "        action_list.append(json.dumps(action))  \n",
    "        action_list.append(json.dumps(doc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89e63de8770f628c77675a9211c73c50d8048a4fbbbf8de889960f40f43afefe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
