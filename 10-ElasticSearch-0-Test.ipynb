{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Data into ES -0-Test**\n",
    "Testing try to bulk load data into ElasticSearch Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "elasticsearch.client.indices.IndicesClient"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- Create an ES Client -------------------------\n",
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch(\n",
    "    \"localhost:9200\",\n",
    "    http_auth=[\"elastic\", \"changeme\"], \n",
    ") \n",
    "# ------------------------- Create an ES Index Client -------------------------\n",
    "from elasticsearch.client import IndicesClient\n",
    "es_index_client = IndicesClient(es_client)\n",
    "type(es_index_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/3qy8wy6s2571t48bzrjk5vl80000gn/T/ipykernel_38909/3029866595.py:79: DeprecationWarning: The 'body' parameter is deprecated for the 'create' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  es_index_client.create(index=\"esg_report_1\", body=configurations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'esg_report_1'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- Define the Settings & Mappings - Ver.1 -------------------------\n",
    "configurations = {\n",
    "  \"settings\": {\n",
    "      \"index\": {\n",
    "          \"number_of_replicas\": 1},\n",
    "      \"analysis\": {\n",
    "          \"filter\": {\n",
    "              \"ngram_filter\": {\n",
    "                \"type\": \"edge_ngram\",\n",
    "                \"min_gram\": 2,\n",
    "                \"max_gram\": 50}\n",
    "          },\n",
    "          \"analyzer\": {\n",
    "              \"ngram_analyzer\": {\n",
    "                  \"type\": \"custom\",\n",
    "                  \"tokenizer\": \"standard\",\n",
    "                  \"filter\": [\n",
    "                    \"lowercase\",\n",
    "                    \"ngram_filter\"]\n",
    "              }\n",
    "          }\n",
    "      }\n",
    "  },\n",
    "  \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\n",
    "                \"type\": \"long\"},\n",
    "            \"label\": {\n",
    "                \"type\": \"long\"},\n",
    "            \"company\": {\n",
    "                \"type\": \"text\"},\n",
    "            \"industry\": {\n",
    "                \"type\": \"text\"},\n",
    "            \"country\": {\n",
    "                \"type\": \"text\"},\n",
    "            \"date\": {\n",
    "                \"type\": \"text\"},\n",
    "            \"content\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"standard\",\n",
    "                \"fields\": {\n",
    "                    \"keyword\": {\n",
    "                        \"type\": \"keyword\"},\n",
    "                    \"ngrams\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"analyzer\": \"ngram_analyzer\"}\n",
    "                }\n",
    "                # \"type\": \"nested\",\n",
    "                # \"properties\": {\n",
    "                    #-------------------\n",
    "                    # \"attribute_name\": {\n",
    "                    #     \"type\": \"text\"},\n",
    "                    # \"attribute_value\": {\n",
    "                    #     \"type\": \"text\"}\n",
    "                    #-------------------\n",
    "                    # \"page\": {\n",
    "                    #     \"type\": \"long\"},\n",
    "                    # \"priority\": {\n",
    "                    #     \"type\": \"float\"},\n",
    "                    # \"sentence\": {\n",
    "                    #     \"type\": \"text\",\n",
    "                    #     \"analyzer\": \"standard\",\n",
    "                    #     \"fields\": {\n",
    "                    #         \"keyword\": {\n",
    "                    #             \"type\": \"keyword\"},\n",
    "                    #         \"ngrams\": {\n",
    "                    #             \"type\": \"text\",\n",
    "                    #             \"analyzer\": \"ngram_analyzer\"}\n",
    "                    #     }\n",
    "                    # }\n",
    "                    #-------------------\n",
    "                # }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# ------------------------- Create an ES Index -------------------------\n",
    "es_index_client.create(index=\"esg_report_1\", body=configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index with new configurations\n",
    "# in Kibana:    DELETE esg_report_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of positive CSV files: 196\n",
      "Type of pos_file_list items: <class 'str'>\n",
      "Total number of negative CSV files: 177\n",
      "Type of pos_file_list items: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# List all trimmed CSV files from the Crawler\n",
    "pos_file_list = os.listdir(\"Crawler & Processing/2.Develop - Crawler Folder/preprocessed/trimmed/pos\")\n",
    "pos_file_list.sort()\n",
    "print(\"Total number of positive CSV files:\", len(pos_file_list))\n",
    "print(\"Type of pos_file_list items:\", type(pos_file_list[0]))\n",
    "# print(\"Show the pos_file_list:\", pos_file_list)\n",
    "\n",
    "neg_file_list = os.listdir(\"Crawler & Processing/2.Develop - Crawler Folder/preprocessed/trimmed/neg\")\n",
    "neg_file_list.sort()\n",
    "print(\"Total number of negative CSV files:\", len(neg_file_list))\n",
    "print(\"Type of pos_file_list items:\", type(neg_file_list[0]))\n",
    "# print(\"Show the pos_file_list:\", neg_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>Issuer - subsidiary</th>\n",
       "      <th>Issuer industry</th>\n",
       "      <th>Country of risk</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4047</td>\n",
       "      <td>Beijing Enterprises Water Capital Management H...</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>China</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16478</td>\n",
       "      <td>Nanjing Financial City Construction &amp; Developm...</td>\n",
       "      <td>Financials</td>\n",
       "      <td>China</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16481</td>\n",
       "      <td>Suzhou Tech City Development Group Co Ltd</td>\n",
       "      <td>Financials</td>\n",
       "      <td>China</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16479</td>\n",
       "      <td>Landesbank Baden-Wuerttemberg</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16480</td>\n",
       "      <td>City of Lunds Sweden</td>\n",
       "      <td>Government</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique ID                                Issuer - subsidiary  \\\n",
       "0       4047  Beijing Enterprises Water Capital Management H...   \n",
       "1      16478  Nanjing Financial City Construction & Developm...   \n",
       "2      16481          Suzhou Tech City Development Group Co Ltd   \n",
       "3      16479                      Landesbank Baden-Wuerttemberg   \n",
       "4      16480                               City of Lunds Sweden   \n",
       "\n",
       "  Issuer industry Country of risk       Date  \n",
       "0       Utilities           China 2021-04-30  \n",
       "1      Financials           China 2021-04-30  \n",
       "2      Financials           China 2021-04-30  \n",
       "3      Financials         Germany 2021-04-30  \n",
       "4      Government          Sweden 2021-04-30  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load companies.xlsx for company info\n",
    "com_details = pd.read_excel(\"Crawler & Processing/2.Develop - Crawler Folder/companies.xlsx\")\n",
    "\n",
    "# Display df info\n",
    "com_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check out pos_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>company</th>\n",
       "      <th>industry</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Aurubis AG</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Lenzing AG</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2020-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13494</td>\n",
       "      <td>1</td>\n",
       "      <td>Liberty Utilities Finance GP 1</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2020-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13498</td>\n",
       "      <td>1</td>\n",
       "      <td>Falck Renewables SpA</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2020-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13770</td>\n",
       "      <td>1</td>\n",
       "      <td>Union Electric Co</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>United States</td>\n",
       "      <td>2020-10-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id label                         company   industry        country  \\\n",
       "0     11     1                      Aurubis AG  Materials        Germany   \n",
       "1     12     1                      Lenzing AG  Materials        Austria   \n",
       "2  13494     1  Liberty Utilities Finance GP 1  Utilities         Canada   \n",
       "3  13498     1            Falck Renewables SpA  Utilities          Italy   \n",
       "4  13770     1               Union Electric Co  Utilities  United States   \n",
       "\n",
       "         date  \n",
       "0  2020-06-10  \n",
       "1  2020-01-10  \n",
       "2  2020-09-16  \n",
       "3  2020-09-16  \n",
       "4  2020-10-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pos_df: (196, 6)\n"
     ]
    }
   ],
   "source": [
    "####### Create df for Positive Reports listed in pos_file_list\n",
    "column_names = [\"id\", \"label\", \"company\", \"industry\", \"country\", \"date\"]\n",
    "\n",
    "pos_df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for file in pos_file_list:\n",
    "    # Get the file name without \".csv\"\n",
    "    pdf_ID = int(file.split(\".\")[0])\n",
    "    # Positive label defined as 1\n",
    "    pos_label = 1\n",
    "    # Find matched rows for each pdf_ID and get the first row to match \"trimmed\" csv files\n",
    "    matched_row = com_details[com_details[\"Unique ID\"]==pdf_ID].iloc[0] \n",
    "    company_name = matched_row[\"Issuer - subsidiary\"]\n",
    "    industry_name = matched_row[\"Issuer industry\"]\n",
    "    country_name = matched_row[\"Country of risk\"]\n",
    "    date_str = str(matched_row[\"Date\"]).split(\" \")[0]\n",
    "    \n",
    "    pos_df = pos_df.append({\"id\": pdf_ID, \n",
    "                            \"label\": pos_label, \n",
    "                            \"company\": company_name, \n",
    "                            \"industry\": industry_name, \n",
    "                            \"country\": country_name,\n",
    "                            \"date\": date_str}, ignore_index=True)\n",
    "\n",
    "print(\"Check out pos_df:\")\n",
    "display(pos_df.head())\n",
    "print(\"Shape of pos_df:\", pos_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check out neg_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>company</th>\n",
       "      <th>industry</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "      <td>-1</td>\n",
       "      <td>Mercon BV</td>\n",
       "      <td>Consumer staples</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>-1</td>\n",
       "      <td>Nokian Renkaat Oyj</td>\n",
       "      <td>Consumer discretionary</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>Aurubis AG</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124</td>\n",
       "      <td>-1</td>\n",
       "      <td>Vinte Viviendas Integrales SAB de CV</td>\n",
       "      <td>Consumer discretionary</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>-1</td>\n",
       "      <td>Obayashi Corp</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id label                               company                industry  \\\n",
       "0  110    -1                             Mercon BV        Consumer staples   \n",
       "1  112    -1                    Nokian Renkaat Oyj  Consumer discretionary   \n",
       "2   11    -1                            Aurubis AG               Materials   \n",
       "3  124    -1  Vinte Viviendas Integrales SAB de CV  Consumer discretionary   \n",
       "4  127    -1                         Obayashi Corp             Industrials   \n",
       "\n",
       "       country  date  \n",
       "0  Netherlands  2018  \n",
       "1      Finland  2018  \n",
       "2      Germany  2019  \n",
       "3       Mexico  2018  \n",
       "4        Japan  2018  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of neg_df: (177, 6)\n"
     ]
    }
   ],
   "source": [
    "####### Create df for Negative Reports listed in neg_file_list\n",
    "column_names = [\"id\", \"label\", \"company\", \"industry\", \"country\", \"date\"]\n",
    "\n",
    "neg_df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for file in neg_file_list:\n",
    "    # Get the file name without \".csv\"\n",
    "    pdf_ID = int(file.split(\"_\")[0])\n",
    "    # Positive label defined as -1\n",
    "    pos_label = -1\n",
    "    # Find matched rows for each pdf_ID and get the first row to match \"trimmed\" csv files\n",
    "    matched_row = com_details[com_details[\"Unique ID\"]==pdf_ID].iloc[0] \n",
    "    company_name = matched_row[\"Issuer - subsidiary\"]\n",
    "    industry_name = matched_row[\"Issuer industry\"]\n",
    "    country_name = matched_row[\"Country of risk\"]\n",
    "    date_str = str(file.split(\".\")[0]).split(\"_\")[1] # Use the date contained in file name\n",
    "    \n",
    "    neg_df = neg_df.append({\"id\": pdf_ID, \n",
    "                            \"label\": pos_label, \n",
    "                            \"company\": company_name, \n",
    "                            \"industry\": industry_name, \n",
    "                            \"country\": country_name,\n",
    "                            \"date\": date_str}, ignore_index=True)\n",
    "\n",
    "print(\"Check out neg_df:\")\n",
    "display(neg_df.head())\n",
    "print(\"Shape of neg_df:\", neg_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 'page', 'priority': 'priority', 'content': 'content'}\n",
      "{'page': '23', 'priority': '0.3846153846153846', 'content': 'In order to assess the environmental impact of material . and energy consumption independently of changes in . production and demand, such consumption is linked to . a functional unit (production of one million writing .  instruments).'}\n",
      "{'page': '23', 'priority': '0.15384615384615385', 'content': 'In 2017/18, waste water intensity has been reduced by . one percent and CO2 emissions by eight percent. At  . 18 percent, the amount of waste per million writing .  instruments has fallen significantly. The reason for the . previous increase was the construction of a water tank . at the Stein site (Germany), whose excavated earth . caused waste quantities to rise. If we consider direct . energy used from non-renewable and renewable sources . in combination with energy purchased, the intensity . decreases by five percent. This is because less direct . energy was produced from renewable energy sources. . In the long term, Faber-Castell intends to counter  . the slight increase in plastic packaging with a global . changeover to fibre-based (paper) packaging.'}\n",
      "{'page': '23', 'priority': '0.923076923076923', 'content': 'Category Unit. FY  . 2014 / 15. FY . 2015 / 16. FY  . 2016 / 17 . FY  . 2017 / 18 . Δ 2016 / 17  . 2017 / 18'}\n",
      "{'page': '23', 'priority': '0.6153846153846154', 'content': 'Effluent (waste water). m3 / Mio. pcs..  52,13   41,12   49,40   49,04  -1 %'}\n",
      "{'page': '23', 'priority': '0.7692307692307692', 'content': 'CO2 emissions t CO2e / Mio. pcs.  12,88   11,53   14,09   13,00  -8 %'}\n",
      "{'page': '23', 'priority': '0.8461538461538461', 'content': 'Total waste t / Mio. pcs.  1,97   1,33   2,01   1,66  -18 %'}\n",
      "{'page': '23', 'priority': '0.4615384615384615', 'content': 'Energy from Scope 1 & Scope 2 MWh / Mio. pcs.  55,30   48,97   60,87   57,72  -5 %'}\n",
      "{'page': '23', 'priority': '0.6923076923076923', 'content': 'Plastic packaging t / Mio. pcs.  0,46   0,40   0,47   0,54  15 %'}\n",
      "{'page': '23', 'priority': '0.23076923076923075', 'content': 'KPI based Mio. pcs of products'}\n",
      "{'page': '23', 'priority': '0.3076923076923077', 'content': 'Challenges . The decentralised organisational structure of the . Faber-Castell Group and regional product lines means . product variety ranges from wood-cased pencils and . coloured pencils, plastic pencils and markers, erasers, . modelling clay, wax crayons through to cosmetic pencils . and applications. Work is being undertaken on the . cross-national implementation of targets and projects . by means of regular exchange between the countries in . a joint sustainability cluster. This requires an analysis . of individual markets, the availability of resources and . the consideration of specific restrictions in order to  . be able to achieve the overriding targets with custom . measures.'}\n",
      "{'page': '23', 'priority': '0.07692307692307693', 'content': 'The KPIs shown here have changed compared to the factsheet 2018 due to a changed database.'}\n",
      "{'page': '23', 'priority': '1.0', 'content': 'Environmental Indicators'}\n",
      "{'page': '23', 'priority': '0.5384615384615384', 'content': '24'}\n",
      "{'page': '24', 'priority': '0.6538461538461539', 'content': 'Environmental figures'}\n",
      "{'page': '24', 'priority': '0.23076923076923075', 'content': '52.13 m3'}\n",
      "{'page': '24', 'priority': '0.8076923076923077', 'content': '41.12 m3. 49.40 m3'}\n",
      "{'page': '24', 'priority': '0.2692307692307692', 'content': '2014 / 15 2016 / 17 2015 / 16'}\n",
      "{'page': '24', 'priority': '0.7692307692307692', 'content': 'Effluent . (m3 / Mio. pcs. writing instruments). CO2-Emissons. (t / Mio. pcs. writing instruments)'}\n",
      "{'page': '24', 'priority': '0.923076923076923', 'content': '12.88 t. 11.53 t. 13.00 t'}\n",
      "{'page': '24', 'priority': '0.7307692307692308', 'content': 'Total waste . (t / Mio. pcs. writing instruments). Energy from Scope 1 & Scope 2 . (MWh / Mio. pcs. writing instruments)'}\n",
      "{'page': '24', 'priority': '1.0', 'content': '-1 %. -8 %'}\n",
      "{'page': '24', 'priority': '0.3076923076923077', 'content': '-18 %'}\n",
      "{'page': '24', 'priority': '0.576923076923077', 'content': 'Plastic Packaging . (t / Mio. pcs. writing instruments)'}\n",
      "{'page': '24', 'priority': '0.1923076923076923', 'content': '2017 / 18'}\n",
      "{'page': '24', 'priority': '0.5', 'content': '49.04 m3'}\n",
      "{'page': '24', 'priority': '0.3461538461538461', 'content': '2014 / 15 2016 / 17 2015 / 16 2017 / 18'}\n",
      "{'page': '24', 'priority': '0.15384615384615385', 'content': '14.09 t'}\n",
      "{'page': '24', 'priority': '0.4423076923076924', 'content': '2014 / 15 2016 / 17 2015 / 16 2017 / 18'}\n",
      "{'page': '24', 'priority': '0.038461538461538464', 'content': '1.97 t'}\n",
      "{'page': '24', 'priority': '0.07692307692307693', 'content': '1.33 t'}\n",
      "{'page': '24', 'priority': '0.9615384615384616', 'content': '2.01 t. 1.66 t'}\n",
      "{'page': '24', 'priority': '0.3846153846153846', 'content': '2014 / 15 2016 / 17 2015 / 16 2017 / 18'}\n",
      "{'page': '24', 'priority': '0.8846153846153847', 'content': '0.46 t. 0.40 t. 0.47 t'}\n",
      "{'page': '24', 'priority': '0.6153846153846154', 'content': '+15 %'}\n",
      "{'page': '24', 'priority': '0.11538461538461538', 'content': '0.54 t'}\n",
      "{'page': '24', 'priority': '0.4423076923076924', 'content': '2014 / 15 2016 / 17 2015 / 16 2017 / 18'}\n",
      "{'page': '24', 'priority': '0.5384615384615384', 'content': '-5 %'}\n",
      "{'page': '24', 'priority': '0.8461538461538461', 'content': '55.30 MWh48.97 MWh. 60.87 MWh 57.72 MWh'}\n",
      "{'page': '24', 'priority': '0.6923076923076923', 'content': '25'}\n",
      "{'page': '25', 'priority': '0.14285714285714288', 'content': 'The United Nations General Assembly adopted the Sus-. tainable Development Goals (SDGs) in 2015. Five core . messages5 were defined, which precede the 17 sustainability . goals (with 169 sub-goals) as a code of conduct. The UN’s . sustainability goals reflect the most important factors for . the creation of a world community by 2030 that is eco-. nomically, socially and environmentally sustainable. It is . groundbreaking in this respect that all associated states  . of the United Nations have committed themselves to the . concrete goals and that a broad civil society has worked . together to develop the goals. For the ambitious goals to be . achieved, all central actors – from the general population, . science, states, local authorities and the private sector – . are called upon to participate in Agenda 2030 and the . change process. Faber-Castell, too, wishes to contribute . and integrate the relevant SDGs into its strategy.'}\n",
      "{'page': '25', 'priority': '0.42857142857142855', 'content': 'Implementation of the SDGs at Faber-Castell. As a first step, Faber-Castell prepared an environment . analysis in order to prioritise the 17 goals in terms of . their relevance to the company and to define fields  . of action. Faber-Castell considers the following goals  . to be decisive for the company to make a positive .  contribution:'}\n",
      "{'page': '25', 'priority': '0.8571428571428571', 'content': '›  Nr. 8: Decent work and economic growth  .  .  ›  Nr. 9: Industry, innovation and infrastructure  .  .  ›  Nr. 12: Responsible consumption and production  .  .  ›  Nr. 13: Climate action  .  .  ›  Nr. 15 Life on land'}\n",
      "{'page': '25', 'priority': '0.5714285714285715', 'content': '5 The 5 core messages (5 Ps):. People – Poverty and hunger must be brought to an end  . so that people can live their lives and fulfil their potential with . dignity. . Planet – Natural resources must be preserved and climate . change measures taken to ensure that present and future . generations can live in an intact environment.. Prosperity – Prosperity for all must be encouraged and all . people should participate in economic, social and technical . progress.. Peace – A life in peace must be promoted, with a society . without fear and violence.. Partnerships – Global partnerships must be developed so . that the goals can be achieved together through international . cooperation.'}\n",
      "{'page': '25', 'priority': '0.2857142857142857', 'content': 'For Faber-Castell, the goals No. 1 (No poverty), No. 2 . (Zero hunger), No. 3 (Good health and well-being), No. 4 . (Quality education), No. 5 (Gender equality) and No. 10 . (Reduced inequalities) are an integral part of the goal of . decent work and economic growth. The goals can be sup-. ported through complying with the Social Charter, since . Faber-Castell employees, for example, have safe working . conditions, receive regular fair payments and have access . to clean drinking water.. The goals already set by Faber-Castell were compared . and linked with the SDGs (see page 30f). In the coming . years, the analysis and work on the United Nations’ goals . will be integrated into the stakeholder survey for 2020 . and further concrete goals and indicators will be defined . based on the results.'}\n",
      "{'page': '25', 'priority': '1.0', 'content': 'The United Nations’  . Sustainable Development Goals'}\n",
      "{'page': '25', 'priority': '0.7142857142857143', 'content': '26'}\n",
      "{'page': '26', 'priority': '0.5', 'content': 'The 17 Sustainable Development Goals of the United Nations'}\n",
      "{'page': '26', 'priority': '1.0', 'content': '27'}\n",
      "{'page': '27', 'priority': '0.2333333333333333', 'content': 'Employees.  › Out of all our employees, 72 percent work in (extended) . production, 28 percent in administration and man-. agement. The proportion of women has remained . constant at 44 percent.  . Although the global proportion of employees with . disabilities has fallen slightly in absolute terms, it . has remained constant over the years at two percent.'}\n",
      "{'page': '27', 'priority': '0.2', 'content': 'Faber-Castell Social Charter.  › In March 2000, Faber-Castell and trade union IG . Metall signed the Faber-Castell Social Charter. This . internationally valid agreement is one of the first  . of its kind in terms of its scope. It sets out Faber-'}\n",
      "{'page': '27', 'priority': '0.16666666666666669', 'content': 'Castell’s voluntary commitment to ensure, throughout . the group of companies, the employment and working . conditions recommended by the International Labour . Organization (ILO). . The Faber-Castell Social Charter includes, among . other things, the prohibition of child labour, equal . opportunities and equal treatment irrespective of . race, religion, gender or nationality and the guarantee . of safe and hygienic working conditions. An inde-. pendent committee monitors the implementation of . the agreement at regular intervals. To this end, two . sites are audited every year. In 2017 these were Ger-. many and Austria, in 2018 the three plants in Brazil . and in early 2019 Peru and Colombia were certified.'}\n",
      "{'page': '27', 'priority': '0.4', 'content': 'Employees Unit. FY  . 2014 / 15. FY  . 2015 / 16. FY  . 2016 / 17 . FY  . 2017 / 18 . Δ 2016 / 17  . 2017 / 18'}\n",
      "{'page': '27', 'priority': '0.1', 'content': '405'}\n",
      "{'page': '27', 'priority': '0.3', 'content': 'Total number of employees. Number  8,076   8,285   8,581  8,063. -6.04 %'}\n",
      "{'page': '27', 'priority': '0.7333333333333333', 'content': 'of which are females. Number  3,543   3,752   3,805  3,478. -8.60 %'}\n",
      "{'page': '27', 'priority': '0.9', 'content': '% 44  45  44  43'}\n",
      "{'page': '27', 'priority': '0.8', 'content': 'of which are handicapped. Number  132   143   139  128. -7.94 %'}\n",
      "{'page': '27', 'priority': '0.9333333333333332', 'content': '% 2  2  2  2'}\n",
      "{'page': '27', 'priority': '0.7', 'content': 'of which work in management / . administration. Number  2,288   2,275   2,317  2,276. -1.77 %'}\n",
      "{'page': '27', 'priority': '0.8666666666666667', 'content': '% 28  27  27  28'}\n",
      "{'page': '27', 'priority': '0.6666666666666667', 'content': 'of which work in production. Number.  5,788 .  6,010   6,264  5787. -7.62 %'}\n",
      "{'page': '27', 'priority': '0.8333333333333333', 'content': '% 72  73  73  72'}\n",
      "{'page': '27', 'priority': '0.4666666666666666', 'content': 'Social Charter Unit. FY . 2014 / 15. FY  . 2015 / 16. FY  . 2016 / 17 . FY  . 2017 / 18'}\n",
      "{'page': '27', 'priority': '0.06666666666666668', 'content': '407'}\n",
      "{'page': '27', 'priority': '0.03333333333333333', 'content': 'Total number of production and . sales sites within the scope of the . Social Charter'}\n",
      "{'page': '27', 'priority': '0.43333333333333335', 'content': 'Number  38   38   38   38'}\n",
      "{'page': '27', 'priority': '0.7666666666666667', 'content': '% 100 100 100 100'}\n",
      "{'page': '27', 'priority': '0.5', 'content': 'Total number of production Sites . with a collective agreement. % not queried 87 87 87'}\n",
      "{'page': '27', 'priority': '0.33333333333333337', 'content': 'Diseases, injuries and deaths Unit. FY  . 2014 / 15. FY . 2015 / 16. FY  . 2016 / 17 . FY  . 2017 / 18 . Δ 2016 / 17  . 2017 / 18'}\n",
      "{'page': '27', 'priority': '0.13333333333333333', 'content': '403'}\n",
      "{'page': '27', 'priority': '0.6333333333333333', 'content': 'Total number of first-aid responders. Number  580   623   784  775. -1.15 %'}\n",
      "{'page': '27', 'priority': '1.0', 'content': '% 7 8 9 10. –'}\n",
      "{'page': '27', 'priority': '0.5666666666666667', 'content': 'Total number of reportable injuries . (including commute). Number  121   114   82  85. 3.66 %'}\n",
      "{'page': '27', 'priority': '0.36666666666666653', 'content': 'Total number of reportable deaths Number 0 0 0 0. 0 %'}\n",
      "{'page': '27', 'priority': '0.5333333333333333', 'content': 'Human rights Unit. FY  . 2014 / 15. FY . 2015 / 16. FY . 2016 / 17 . FY  . 2017 / 18'}\n",
      "{'page': '27', 'priority': '0.6', 'content': '406. Total number of reported cases  . of discrimination and corruption. Number 0 0 0 0'}\n",
      "{'page': '27', 'priority': '0.9666666666666668', 'content': 'Social Indicators'}\n",
      "{'page': '27', 'priority': '0.26666666666666666', 'content': '28'}\n",
      "{'page': '28', 'priority': '1.0', 'content': 'European factories as well as India and Indonesia are . planned for 2020.'}\n",
      "{'page': '28', 'priority': '0.42857142857142855', 'content': 'Sickness, injuries, deaths.  › The number of reported work-related accidents .  (including accidents which occur during the commute . to or from work) has risen slightly from 82 to 85 . accidents in comparison to 2016/17. Compared  . to the 2014/15 financial year, however, the number  . of reportable accidents fell by almost 30 percent.'}\n",
      "{'page': '28', 'priority': '0.7142857142857143', 'content': 'Training and further education.  › In addition to the legally required training courses, . such as on occupational safety, the company also . offers language and IT courses as well as intercultural . workshops. The Faber-Castell vision “We unleash . creative potential” is also promoted by creative activities . and workshops for employees. .  . Each employee’s training needs are determined during . an annual interview between the employee and his or . her supervisor as part of the “Employee Development . Programme” and, if possible, appropriate training is . planned for the following year..  . Human rights.  › As part of the data collection process for the FIS .  report6 , cases of discrimination and corruption can . also be reported and monitored. Compliance with . human rights is also regularly checked by the social . audits. Violations of applicable law, human rights  . and working conditions can also be reported via the .  Compliance Management System.'}\n",
      "{'page': '28', 'priority': '0.14285714285714288', 'content': '6 The FIS report is based on the FABIQUS Information System. . FABIQUS is the abbreviation for the Faber-Castell integrated . management system for quality, environment and social .  affairs. Faber-Castell collects and analyses all of this non- . financial information from all its production sites, and consoli-. dates it annually in the FIS report.'}\n",
      "{'page': '28', 'priority': '0.5714285714285715', 'content': 'How we act fairly and correctly:  . the new Faber-Castell Charter. The corporate success of . Faber-Castell is based on . trusting and fair dealings . with employees, business . partners, customers and . suppliers. These values . have not only been prac-. tised in the company for . many generations, they are also the principles of the . “Honourable Merchant”, a model dating back to the . Middle Ages, which is still relevant centuries later. . The honourable merchant is committed to adhering . to values and rules, but also creates the conditions . for honourable action and assumes responsibility for . his deeds. As part of the Compliance Management . System (“CMS”), a code of conduct was drawn up  . in cooperation between the Faber-Castell family, the . Supervisory Board, the Executive Board and the . Compliance Committee: the Faber-Castell Charter.  . It lists 15 points that help every employee to act .  fairly and transparently – in line with our corporate . values. “The binding Code of Conduct is intended  . to give employees throughout the company guidance . and security,” says Thomas Wagner, Head of .  Compliance. An independent lawyer also provides . support as an ombudsman, whom employees can . contact anonymously. The Code of Conduct sets out . what has been part of our philosophy for centuries: . fairness, transparency and respect. Only in this way . can we maintain the high brand confidence among . our customers and ensure the profitable growth of . the company – in the spirit of an honourable merchant.'}\n",
      "{'page': '28', 'priority': '0.2857142857142857', 'content': 'Challenges. Faber-Castell adopted a socially responsible approach at . an early stage. One of the first company health insurance . funds in Germany was founded as early as 1844, the . first nursery school was opened in Stein in 1851 and in . 1865 apartments were made available for workers. The . signing of the Social Charter in 2000 was another .  important step forward in terms of working and employ-. ment conditions. Strict cooperation with local companies . and independent partners such as trade unions, adapted . to the conditions in each country, is crucial for imple-. menting the Social Charter in practice. Being successful . as a company in the long term requires motivated and . satisfied employees to carry the company into the future . through creativity, innovation, enthusiasm and curiosity. . Rapidly changing market conditions, rapid technological . progress, compatibility of family and career and the . work/life balance are basic conditions that demand .  flexible working conditions. Custom continuing education . and further training programmes, attractive employment . conditions and respect for social responsibility on the . part of a family business are indispensable for Faber-. Castell.'}\n",
      "{'page': '28', 'priority': '0.8571428571428571', 'content': '29'}\n",
      "{'page': '29', 'priority': '0.4166666666666666', 'content': 'Status'}\n",
      "{'page': '29', 'priority': '0.5833333333333334', 'content': 'Extended use of local wood resources and use of certified wood . All wood-cased pencils produced by Faber-Castell are made of certified wood . Faber-Castell’s next step is to make even greater use of local resources in order  . to minimise transport distances. Currently, regional and local wood is tested .  regarding its suitability for the production of high quality pencils.'}\n",
      "{'page': '29', 'priority': '0.33333333333333337', 'content': 'Continuous'}\n",
      "{'page': '29', 'priority': '0.6666666666666667', 'content': 'Plastics: strategy for alternative plastics resources. The Faber-Castell Group is committed to improve the environmental balance in the . future by increasing the proportion of recycled plastics or non-conventional plastics. . This applies both to packaging and to the products. The company is currently .  examining several alternative materials. Two product groups are already manufac-. tured from recycled plastics: both the Ecco Pigment and the Textilmarker consist . mainly of recycled material.'}\n",
      "{'page': '29', 'priority': '0.125', 'content': 'In progress'}\n",
      "{'page': '29', 'priority': '0.8333333333333333', 'content': 'Packaging: Reduction of plastic packaging . The aim is to reduce the proportion of plastic in packaging by five percent each . year. In the coming years, existing plastic packaging will gradually be replaced by . degradable materials such as paper fibres, or recycled plastic. Pilot projects and .  actions are currently being initiated. The results and experiences will be incorporated . into a Group-wide strategy.'}\n",
      "{'page': '29', 'priority': '0.125', 'content': 'In progress'}\n",
      "{'page': '29', 'priority': '0.75', 'content': 'Monitoring carbon emissions. An annual analysis of the carbon emissions from all production sites is used as a tool . to identify hotspots and to develop strategies to reduce emissions. According to current . analyses, freight transport, as well as the amount of purchased energy, also offer .  considerable savings potential for the coming year.'}\n",
      "{'page': '29', 'priority': '0.25', 'content': 'In progress'}\n",
      "{'page': '29', 'priority': '0.5', 'content': 'Targets and progress'}\n",
      "{'page': '29', 'priority': '1.0', 'content': 'Targets and Progress'}\n",
      "{'page': '29', 'priority': '0.9166666666666669', 'content': '30'}\n",
      "{'page': '30', 'priority': '0.7272727272727273', 'content': 'Customer Care Centre (CCC): Optimisation of processes in complaint handling . through new software with a SAP connection, including invoicing and inventory . management, as well as through the introduction of a warranty policy. The warranty policy was introduced worldwide. Regarding the return of goods, the customer care centre in Stein reduced packaging . waste by 60 percent and plastic waste by 92 percent. The CCC software is integrated . into the worldwide Customer Care Centres and the global processes are continuously . being analysed and optimised.'}\n",
      "{'page': '30', 'priority': '0.4545454545454545', 'content': 'Completed'}\n",
      "{'page': '30', 'priority': '0.6363636363636364', 'content': 'Increasing the share of renewable energy through purchasing. Currently, 31 percent of the Group’s global energy demand is purchased, 63 percent of . which comes from renewable sources. Brazil and Austria have already been able to switch . entirely to green electricity, and other countries are set to follow. Among others, 100 per-. cent of the electricity purchased for the sites in Germany is to come from renewable . sources from 2020 onwards.'}\n",
      "{'page': '30', 'priority': '0.2727272727272727', 'content': 'In progress'}\n",
      "{'page': '30', 'priority': '0.8181818181818181', 'content': 'Life cycle assessment. After a life cycle assessment for wood-cased pencils manufactured in Brazil was .  prepared in 2017, further quantitative assessments of other product groups are to follow . to detail the product-specific environmental impacts. The next step is to analyse the . highlighters produced in Austria and Brazil.'}\n",
      "{'page': '30', 'priority': '0.13636363636363635', 'content': 'In progress'}\n",
      "{'page': '30', 'priority': '1.0', 'content': 'Updating the stakeholder analysis . The existing stakeholder survey is to be updated for 2020 and adapted to existing . standards and targets, such as the Sustainable Development Goals (SDGs) or Global . Reporting Initiative (GRI). The aim of the stakeholder survey is to define and prioritise . relevant topics.'}\n",
      "{'page': '30', 'priority': '0.13636363636363635', 'content': 'In progress'}\n",
      "{'page': '30', 'priority': '0.5454545454545454', 'content': 'Modernisation of the Stein pelletising furnace . By modernising the existing furnace, in future it will be possible to maintain the . combustion of waste wood for 72 hours. This increase in capacity will result in less . waste and will significantly reduce the oil and gas resources required for heating.'}\n",
      "{'page': '30', 'priority': '0.3636363636363637', 'content': 'In progress'}\n",
      "{'page': '30', 'priority': '0.9090909090909092', 'content': '31'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"Crawler & Processing/2.Develop - Crawler Folder/preprocessed/trimmed/pos/\" + fileName, \"r\") as f:\n",
    "    csv_file = csv.DictReader(f, fieldnames=columns, delimiter=\",\", quotechar='\"') \n",
    "    for r in csv_file:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Bulk Process Positive Reports\n",
    "columns = [\"page\", \"priority\", \"content\"]\n",
    "index_name = \"esg_report_1\"\n",
    "action_list = []  \n",
    "\n",
    "for fileName in pos_file_list:\n",
    "    pdf_ID = int(fileName.split(\".\")[0])\n",
    "    matched_row = pos_df[pos_df[\"id\"]==pdf_ID].iloc[0] \n",
    "    \n",
    "    # action = {\"index\": {\"_index\": index_name, \"_id\": pdf_ID}}  \n",
    "    # doc = {\n",
    "    #         \"id\": pdf_ID, \n",
    "    #         \"label\": matched_row[\"label\"],\n",
    "    #         \"company\": matched_row[\"company\"],\n",
    "    #         \"industry\": matched_row[\"industry\"],\n",
    "    #         \"country\": matched_row[\"country\"],\n",
    "    #         \"date\": matched_row[\"date\"],\n",
    "    #         }\n",
    "    # action_list.append(json.dumps(action))  \n",
    "    # action_list.append(json.dumps(doc))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # with open(\"Crawler & Processing/2.Develop - Crawler Folder/preprocessed/trimmed/pos/\" + fileName, \"r\") as f:\n",
    "    #     csv_file = csv.DictReader(f, fieldnames=columns, delimiter=\",\", quotechar='\"') \n",
    "    #     next(csv_file)\n",
    "        \n",
    "    # action = {\"index\": {\"_index\": index_name, \"_id\": pdf_ID}}  \n",
    "    # doc = {\n",
    "    #         \"id\": pdf_ID, \n",
    "    #         \"label\": matched_row[\"label\"],\n",
    "    #         \"company\": matched_row[\"company\"],\n",
    "    #         \"industry\": matched_row[\"industry\"],\n",
    "    #         \"country\": matched_row[\"country\"],\n",
    "    #         \"date\": matched_row[\"date\"],\n",
    "    #         \"content\": [\n",
    "    #             for row in csv_file:\n",
    "    #                 {\"page\": row[\"page\"]},\n",
    "    #                 {\"priority\": row[\"priority\"]},\n",
    "    #                 {\"sentence\": row[\"content\"]}]\n",
    "    #         }\n",
    "    # action_list.append(json.dumps(action))  \n",
    "    # action_list.append(json.dumps(doc))\n",
    "    \n",
    "    ###### Concacte all text into one string per doc\n",
    "    content_str = \"\"\n",
    "    with open(\"Crawler & Processing/2.Develop - Crawler Folder/preprocessed/trimmed/pos/\" + fileName, \"r\") as f:\n",
    "        csv_file = csv.DictReader(f, fieldnames=columns, delimiter=\",\", quotechar='\"')\n",
    "        next(csv_file)  \n",
    "        for row in csv_file:\n",
    "            content_str += row[\"content\"]\n",
    "        \n",
    "\n",
    "    action = {\"index\": {\"_index\": index_name, \"_id\": pdf_ID}} \n",
    "    doc = {\n",
    "            \"id\": pdf_ID, \n",
    "            \"label\": matched_row[\"label\"],\n",
    "            \"company\": matched_row[\"company\"],\n",
    "            \"industry\": matched_row[\"industry\"],\n",
    "            \"country\": matched_row[\"country\"],\n",
    "            \"date\": matched_row[\"date\"],\n",
    "            \"content\": content_str\n",
    "                        # [\n",
    "                        # #-------------------\n",
    "                        # # {\"page\": row[\"page\"]},\n",
    "                        # # {\"priority\": row[\"priority\"]},\n",
    "                        # # {\"sentence\": row[\"content\"]}\n",
    "                        # #-------------------\n",
    "                        # # {\"attribute_name\": \"page\", \"attribute_value\": row[\"page\"]},\n",
    "                        # # {\"attribute_name\": \"priority\", \"attribute_value\": row[\"priority\"]},\n",
    "                        # # {\"attribute_name\": \"text\", \"attribute_value\": row[\"content\"]}\n",
    "                        # ]\n",
    "            }\n",
    "    action_list.append(json.dumps(action))  \n",
    "    action_list.append(json.dumps(doc)) \n",
    "\n",
    "# ------------------------- Feed the data into a JSON file -------------------------\n",
    "with open(\"esg_report_1.json\", \"w\") as write_file:\n",
    "    write_file.write(\"\\n\".join(action_list))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 1303,\n",
       " 'errors': True,\n",
       " 'items': [{'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '11',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[75, 101, 121, 32, 109, 101, 97, 115, 117, 114, 101, 115, 32, 111, 102, 32, 116, 104, 101, 32, 83, 117, 115, 116, 97, 105, 110, 97, 98, 105]...\\', original message: bytes can be at most 32766 in length; got 32793',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 32793'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '12',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 1,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '13494',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 2,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '13498',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 3,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '13770',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 4,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '13786',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 5,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '13787',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 6,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '13866',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 7,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '13890',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 8,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14019',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 9,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14226',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 10,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14390',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 11,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14410',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[50, 54, 46, 32, 66, 84, 83, 32, 71, 82, 79, 85, 80, 32, 83, 85, 83, 84, 65, 73, 78, 65, 66, 73, 76, 73, 84, 89, 32, 82]...\\', original message: bytes can be at most 32766 in length; got 37495',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 37495'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14561',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 13,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14658',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 14,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14691',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[73, 78, 84, 69, 71, 82, 65, 84, 69, 68, 32, 82, 69, 80, 79, 82, 84, 32, 69, 78, 71, 73, 69, 32, 50, 48, 50, 48, 46, 32]...\\', original message: bytes can be at most 32766 in length; got 42162',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 42162'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14764',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[69, 110, 118, 105, 114, 111, 110, 109, 101, 110, 116, 97, 108, 32, 82, 101, 112, 111, 114, 116, 67, 111, 114, 112, 111, 114, 97, 116, 101, 32]...\\', original message: bytes can be at most 32766 in length; got 70757',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 70757'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14765',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[87, 101, 32, 97, 114, 101, 32, 117, 110, 105, 113, 117, 101, 108, 121, 32, 46, 32, 112, 111, 115, 105, 116, 105, 111, 110, 101, 100, 32, 116]...\\', original message: bytes can be at most 32766 in length; got 119816',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 119816'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14769',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[67, 108, 105, 109, 97, 116, 101, 32, 67, 104, 97, 110, 103, 101, 32, 97, 110, 100, 32, 46, 32, 69, 110, 101, 114, 103, 121, 32, 77, 97]...\\', original message: bytes can be at most 32766 in length; got 134538',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 134538'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14883',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 19,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '149',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 20,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14922',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[51, 56, 67, 108, 101, 97, 110, 32, 119, 97, 116, 101, 114, 32, 97, 110, 100, 32, 46, 32, 115, 97, 110, 105, 116, 97, 116, 105, 111, 110]...\\', original message: bytes can be at most 32766 in length; got 38915',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 38915'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14932',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[55, 52, 32, 32, 50, 48, 50, 48, 32, 83, 117, 115, 116, 97, 105, 110, 97, 98, 105, 108, 105, 116, 121, 32, 82, 101, 112, 111, 114, 116]...\\', original message: bytes can be at most 32766 in length; got 86574',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 86574'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14961',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 23,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14988',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[50, 53, 50, 46, 32, 50, 53, 51, 49, 32, 47, 67, 104, 97, 105, 114, 109, 97, 110, -30, -128, -103, 115, 32, 76, 101, 116, 116, 101, 114]...\\', original message: bytes can be at most 32766 in length; got 45189',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 45189'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '15061',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[49, 50, 83, 84, 65, 84, 69, 77, 69, 78, 84, 32, 79, 70, 32, 78, 79, 78, 45, 70, 73, 78, 65, 78, 67, 73, 65, 76, 32, 80]...\\', original message: bytes can be at most 32766 in length; got 36468',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 36468'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '15174',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[69, 110, 101, 114, 103, 121, 32, 117, 115, 101, 32, 114, 101, 100, 117, 99, 101, 100, 98, 121, 32, 49, 51, 46, 57, 77, 32, 107, 87, 104]...\\', original message: bytes can be at most 32766 in length; got 69932',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 69932'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '15196',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 27,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '15247',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 28,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '15341',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[48, 49, 56, 69, 110, 118, 105, 114, 111, 110, 109, 101, 110, 116, 97, 108, 84, 104, 101, 9, 69, 117, 114, 111, 112, 101, 97, 110, 9, 85]...\\', original message: bytes can be at most 32766 in length; got 71173',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 71173'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '155',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 30,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '15571',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[69, 78, 86, 73, 82, 79, 78, 77, 69, 78, 84, 65, 76, 32, 77, 65, 78, 65, 71, 69, 77, 69, 78, 84, 67, 79, 77, 77, 73, 84]...\\', original message: bytes can be at most 32766 in length; got 71850',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 71850'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '15625',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[69, 110, 118, 105, 114, 111, 110, 109, 101, 110, 116, 97, 108, 32, 77, 97, 110, 97, 103, 101, 109, 101, 110, 116, 32, 54, 51, 69, 99, 111]...\\', original message: bytes can be at most 32766 in length; got 38136',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 38136'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '15641',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 33,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '15752',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 34,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '15820',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 35,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '15925',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 36,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '160',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 37,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '161',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 38,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '16207',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 39,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '16208',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 40,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '16212',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[69, 110, 101, 114, 103, 121, 32, 46, 32, 82, 101, 100, 117, 99, 116, 105, 111, 110, 32, 97, 110, 100, 46, 32, 69, 102, 102, 105, 99, 105]...\\', original message: bytes can be at most 32766 in length; got 37881',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 37881'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '16217',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[50, 48, 49, 53, 32, 50, 48, 49, 54, 32, 50, 48, 49, 55, 32, 89, 111, 89, 32, 67, 104, 97, 110, 103, 101, 32, 40, 37, 41, 79]...\\', original message: bytes can be at most 32766 in length; got 80201',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 80201'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '16229',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[83, 117, 115, 116, 97, 105, 110, 97, 98, 105, 108, 105, 116, 121, 32, 97, 110, 100, 32, 99, 111, 114, 112, 111, 114, 97, 116, 101, 32, 115]...\\', original message: bytes can be at most 32766 in length; got 76328',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 76328'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '16237',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 44,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '16257',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[49, 53, 52, 85, 110, 105, 116, 101, 100, 32, 77, 105, 99, 114, 111, 101, 108, 101, 99, 116, 114, 111, 110, 105, 99, 115, 32, 67, 111, 114]...\\', original message: bytes can be at most 32766 in length; got 51431',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 51431'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '16263',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 46,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '16276',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 47,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '16281',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[49, 51, 56, 46, 32, 76, 97, 110, 116, 109, -61, -92, 110, 110, 101, 110, 32, 65, 110, 110, 117, 97, 108, 32, 82, 101, 112, 111, 114, 116]...\\', original message: bytes can be at most 32766 in length; got 59395',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 59395'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '16357',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[67, 104, 105, 110, 97, 32, 76, 111, 110, 103, 121, 117, 97, 110, 32, 80, 111, 119, 101, 114, 32, 71, 114, 111, 117, 112, 32, 67, 111, 114]...\\', original message: bytes can be at most 32766 in length; got 63941',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 63941'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '16447',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 50,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '169',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 51,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '17',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 52,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '171',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 53,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '175',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[51, 55, 67, 79, 82, 80, 79, 82, 65, 84, 69, 32, 83, 79, 67, 73, 65, 76, 32, 82, 69, 83, 80, 79, 78, 83, 73, 66, 73, 76]...\\', original message: bytes can be at most 32766 in length; got 82283',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 82283'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '177',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 55,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '17993',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 56,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '18',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 57,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '186',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[50, 48, 79, 116, 116, 111, 32, 71, 114, 111, 117, 112, 32, -30, -128, -109, 32, 65, 110, 110, 117, 97, 108, 32, 82, 101, 112, 111, 114, 116]...\\', original message: bytes can be at most 32766 in length; got 61611',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 61611'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '189',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 59,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '190',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 60,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '193',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 61,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '194',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 62,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '195',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 63,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '196',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 64,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '197',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[84, 104, 101, 32, 102, 111, 114, 101, 115, 116, 32, 114, 101, 115, 101, 114, 118, 101, 115, 32, 32, 46, 32, 111, 102, 32, 69, 117, 114, 111]...\\', original message: bytes can be at most 32766 in length; got 62939',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 62939'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '20',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 66,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '203',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 67,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '207',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 68,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '208',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 69,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '211',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 70,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '214',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 71,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '216',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[51, 54, 47, 47, 32, 50, 48, 49, 57, 32, 67, 111, 114, 112, 111, 114, 97, 116, 101, 32, 83, 111, 99, 105, 97, 108, 32, 69, 110, 103]...\\', original message: bytes can be at most 32766 in length; got 41422',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 41422'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '218',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 73,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '219',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 74,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '22',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 75,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '221',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 76,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '224',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 77,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '228',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[83, 101, 118, 101, 114, 110, 32, 84, 114, 101, 110, 116, 32, 46, 32, 65, 99, 97, 100, 101, 109, 121, 83, 101, 118, 101, 114, 110, 32, 46]...\\', original message: bytes can be at most 32766 in length; got 79844',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 79844'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '23',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 79,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '231',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[49, 56, 46, 32, 84, 111, 112, 32, 67, 111, 109, 109, 105, 116, 109, 101, 110, 116, 32, 83, 117, 115, 116, 97, 105, 110, 97, 98, 105, 108]...\\', original message: bytes can be at most 32766 in length; got 149668',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 149668'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '232',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 81,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '234',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 82,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '235',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 83,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '244',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[84, 104, 101, 114, 101, 32, 119, 101, 114, 101, 32, 110, 111, 32, 104, 101, 97, 108, 116, 104, 45, 98, 97, 115, 101, 100, 32, 100, 114, 105]...\\', original message: bytes can be at most 32766 in length; got 35947',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 35947'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '247',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[100, 97, 116, 97, 32, 99, 101, 110, 116, 101, 114, 32, 104, 97, 115, 32, 98, 114, 111, 117, 103, 104, 116, 32, -30, -126, -84, 49, 46, 50]...\\', original message: bytes can be at most 32766 in length; got 34283',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 34283'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '248',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[46, 111, 112, 101, 114, 97, 116, 105, 111, 110, 115, 32, 32, 40, 117, 110, 108, 101, 115, 115, 32, 32, 111, 116, 104, 101, 114, 119, 105, 115]...\\', original message: bytes can be at most 32766 in length; got 52699',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 52699'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '25',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 87,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '251',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 88,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '252',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[69, 78, 86, 73, 82, 79, 78, 77, 69, 78, 84, 79, 85, 82, 32, 65, 80, 80, 82, 79, 65, 67, 72, 46, 32, 87, 101, 32, 97, 114]...\\', original message: bytes can be at most 32766 in length; got 90759',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 90759'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '256',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 90,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '265',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 91,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '266',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 92,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '268',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 93,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '271',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 94,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '274',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[46, 32, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46]...\\', original message: bytes can be at most 32766 in length; got 75492',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 75492'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '276',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 96,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '277',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[80, 82, 79, 84, 69, 67, 84, 73, 78, 71, 32, 46, 32, 79, 85, 82, 32, 32, 46, 32, 80, 76, 65, 78, 69, 84, 87, 101, -30, -128]...\\', original message: bytes can be at most 32766 in length; got 64992',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 64992'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '279',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 98,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '280',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 99,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '282',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 100,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '283',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 101,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '286',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 102,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '29',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 103,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '295',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 104,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '296',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 105,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '297',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 106,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '303',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 107,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '307',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 108,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '313',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[87, 101, 115, 102, 97, 114, 109, 101, 114, 115, 32, 50, 48, 49, 57, 32, 65, 110, 110, 117, 97, 108, 32, 82, 101, 112, 111, 114, 116, 46]...\\', original message: bytes can be at most 32766 in length; got 38248',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 38248'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '3187',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 110,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '319',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[82, 101, 115, 112, 111, 110, 115, 105, 98, 108, 101, 32, 98, 117, 115, 105, 110, 101, 115, 115, 32, 99, 111, 110, 116, 105, 110, 117, 101, 100]...\\', original message: bytes can be at most 32766 in length; got 37144',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 37144'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '3193',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 112,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '3194',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 113,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '32',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 114,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '321',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[67, 111, 118, 101, 115, 116, 114, 111, 32, 65, 110, 110, 117, 97, 108, 32, 82, 101, 112, 111, 114, 116, 32, 50, 48, 50, 48, 84, 79, 32]...\\', original message: bytes can be at most 32766 in length; got 48866',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 48866'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '323',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 116,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '325',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[49, 48, 54, 32, 80, 73, 82, 69, 76, 76, 73, 32, 65, 78, 78, 85, 65, 76, 32, 82, 69, 80, 79, 82, 84, 32, 50, 48, 50, 48]...\\', original message: bytes can be at most 32766 in length; got 67924',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 67924'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '328',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 118,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '329',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 119,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '33',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 120,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '330',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 121,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '340',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 122,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '345',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[56, 57, 73, 70, 70, 67, 79, 45, 84, 79, 75, 73, 79, -30, -128, -103, 115, 32, 69, 102, 102, 111, 114, 116, 115, 32, 116, 111, 32, 73]...\\', original message: bytes can be at most 32766 in length; got 47911',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 47911'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '351',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 124,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '36',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[65, 110, 110, 117, 97, 108, 32, 82, 101, 112, 111, 114, 116, 32, 50, 48, 50, 48, 32, 32, 32, 32, 32, -30, -122, -105, 32, 83, 117, 115]...\\', original message: bytes can be at most 32766 in length; got 38981',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 38981'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '364',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 126,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '365',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 127,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '376',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[77, 65, 78, 65, 71, 69, 77, 69, 78, 84, 32, 65, 80, 80, 82, 79, 65, 67, 72, 32, 46, 32, 71, 82, 73, 32, 49, 48, 51, 45]...\\', original message: bytes can be at most 32766 in length; got 37294',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 37294'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '38',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 129,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '382',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 130,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '383',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 131,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '384',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[83, 84, 82, 65, 84, 69, 71, 73, 67, 32, 82, 69, 80, 79, 82, 84, 66, 101, 105, 110, 103, 32, 97, 32, 114, 101, 115, 112, 111, 110]...\\', original message: bytes can be at most 32766 in length; got 66459',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 66459'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '387',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 133,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '390',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 134,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '391',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 135,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '392',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[53, 51, 46, 32, 53, 50, 46, 32, 83, 85, 83, 84, 65, 73, 78, 65, 66, 73, 76, 73, 84, 89, 32, 65, 78, 68, 32, 67, 79, 82]...\\', original message: bytes can be at most 32766 in length; got 38843',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 38843'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '393',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[67, 117, 115, 116, 111, 109, 101, 114, 115, 32, 97, 110, 100, 32, 32, 46, 32, 105, 110, 110, 111, 118, 97, 116, 105, 111, 110, 79, 117, 114]...\\', original message: bytes can be at most 32766 in length; got 67509',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 67509'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '396',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[48, 46, 32, 48, 46, 32, 51, 83, 85, 83, 84, 65, 73, 78, 65, 66, 76, 69, 32, 86, 65, 76, 85, 69, 67, 82, 69, 65, 84, 73]...\\', original message: bytes can be at most 32766 in length; got 47243',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 47243'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '397',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 139,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '399',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 140,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '401',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[84, 79, 87, 65, 82, 68, 32, 46, 32, 65, 32, 77, 79, 82, 69, 32, 46, 32, 80, 79, 83, 73, 84, 73, 86, 69, 32, 46, 32, 69]...\\', original message: bytes can be at most 32766 in length; got 44171',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 44171'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '409',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[76, 101, 116, 116, 101, 114, 32, 111, 102, 32, 105, 110, 116, 114, 111, 100, 117, 99, 116, 105, 111, 110, 83, 117, 109, 109, 97, 114, 121, 32]...\\', original message: bytes can be at most 32766 in length; got 58650',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 58650'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '412',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[87, 101, 32, 104, 97, 118, 101, 32, 115, 101, 116, 32, 97, 110, 100, 32, 97, 114, 101, 32, 119, 111, 114, 107, 105, 110, 103, 32, 116, 111]...\\', original message: bytes can be at most 32766 in length; got 48446',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 48446'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '42',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 144,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '429',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 145,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '432',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 146,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '434',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[69, 108, 105, 97, 32, 71, 114, 111, 117, 112, 32, 83, 117, 115, 116, 97, 105, 110, 97, 98, 105, 108, 105, 116, 121, 32, 82, 101, 112, 111]...\\', original message: bytes can be at most 32766 in length; got 49686',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 49686'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '438',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 148,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '442',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 149,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '447',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[84, 101, 114, 110, 97, -30, -128, -103, 115, 32, 109, 97, 105, 110, 32, 99, 111, 110, 116, 114, 105, 98, 117, 116, 105, 111, 110, 32, 116, 111]...\\', original message: bytes can be at most 32766 in length; got 83359',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 83359'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '449',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 151,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '45',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 152,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '451',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 153,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '461',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 154,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '471',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 155,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '474',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[77, 97, 116, 101, 114, 105, 97, 108, 105, 116, 105, 101, 115, 83, 111, 99, 105, 97, 108, 32, 73, 115, 115, 117, 101, 115, 46, 32, 67, 111]...\\', original message: bytes can be at most 32766 in length; got 33356',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 33356'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '477',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 157,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '49',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[83, 116, 97, 116, 117, 116, 111, 114, 121, 32, 83, 117, 115, 116, 97, 105, 110, 97, 98, 105, 108, 105, 116, 121, 32, 82, 101, 112, 111, 114]...\\', original message: bytes can be at most 32766 in length; got 35361',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 35361'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '492',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 159,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '494',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[69, 78, 86, 73, 82, 79, 78, 77, 69, 78, 84, 65, 76, 32, 46, 32, 82, 69, 83, 80, 79, 78, 83, 73, 66, 73, 76, 73, 84, 89]...\\', original message: bytes can be at most 32766 in length; got 82742',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 82742'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '50',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 161,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '511',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[83, 117, 115, 116, 97, 105, 110, 97, 98, 108, 101, 32, 115, 117, 112, 112, 108, 121, 32, 99, 104, 97, 105, 110, 50, 56, 54, 46, 32, 50]...\\', original message: bytes can be at most 32766 in length; got 34962',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 34962'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '512',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[62, 32, 77, 97, 110, 97, 103, 101, 109, 101, 110, 116, -62, -96, 82, 101, 112, 111, 114, 116, 32, -30, -128, -94, 32, 50, 48, 49, 56, 47]...\\', original message: bytes can be at most 32766 in length; got 45136',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 45136'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '514',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[49, 57, 69, 110, 118, 105, 114, 111, 110, 109, 101, 110, 116, 97, 108, 32, 46, 32, 115, 117, 115, 116, 97, 105, 110, 97, 98, 105, 108, 105]...\\', original message: bytes can be at most 32766 in length; got 36752',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 36752'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '522',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 165,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '525',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 166,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '53',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[83, 32, 85, 32, 83, 32, 84, 32, 65, 32, 73, 32, 78, 32, 65, 32, 66, 32, 73, 32, 76, 32, 73, 32, 84, 32, 89, 72, 32, 73]...\\', original message: bytes can be at most 32766 in length; got 77674',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 77674'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '532',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 168,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '539',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 169,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '54',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 170,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '543',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[67, 108, 111, 115, 101, 32, 116, 104, 101, 32, 76, 111, 111, 112, 80, 108, 97, 115, 116, 105, 99, 32, 105, 115, 32, 97, 32, 114, 101, 110]...\\', original message: bytes can be at most 32766 in length; got 66420',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 66420'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '544',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[67, 76, 73, 77, 65, 84, 69, 32, 67, 72, 65, 78, 71, 69, 32, 66, 73, 79, 68, 73, 86, 69, 82, 83, 73, 84, 89, 32, 79, 67]...\\', original message: bytes can be at most 32766 in length; got 32795',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 32795'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '545',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 173,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '547',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[-30, -128, -98, 74, 111, 105, 110, 32, 109, 101, 32, 105, 110, 32, 101, 120, 112, 108, 111, 114, 105, 110, 103, 32, 116, 104, 105, 115, 32, 32]...\\', original message: bytes can be at most 32766 in length; got 234141',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 234141'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '548',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 175,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '556',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[69, 110, 118, 105, 114, 111, 110, 109, 101, 110, 116, 97, 108, 32, 83, 116, 101, 119, 97, 114, 100, 115, 104, 105, 112, 58, 46, 32, 84, 111]...\\', original message: bytes can be at most 32766 in length; got 58868',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 58868'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '557',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[50, 48, 50, 48, 32, 72, 105, 103, 104, 108, 105, 103, 104, 116, 115, 49, 32, 66, 97, 115, 101, 100, 32, 111, 110, 32, 116, 104, 101, 32]...\\', original message: bytes can be at most 32766 in length; got 67969',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 67969'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '560',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 178,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '561',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[55, 55, 46, 32, 65, 78, 78, 85, 65, 76, 32, 82, 69, 80, 79, 82, 84, 32, 50, 48, 50, 49, 46, 32, 83, 117, 115, 116, 97, 105]...\\', original message: bytes can be at most 32766 in length; got 32940',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 32940'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '563',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[66, 117, 105, 108, 100, 105, 110, 103, 32, 97, 32, 104, 111, 108, 105, 115, 116, 105, 99, 32, 46, 32, 98, 117, 115, 105, 110, 101, 115, 115]...\\', original message: bytes can be at most 32766 in length; got 65183',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 65183'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '574',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[50, 52, 48, 46, 32, 50, 52, 48, 32, 50, 52, 49, 46, 32, 83, 117, 115, 116, 97, 105, 110, 97, 98, 105, 108, 105, 116, 121, 32, 82]...\\', original message: bytes can be at most 32766 in length; got 52607',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 52607'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '575',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 182,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '580',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 183,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '588',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 184,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '595',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 185,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '598',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 186,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '599',\n",
       "    'status': 400,\n",
       "    'error': {'type': 'illegal_argument_exception',\n",
       "     'reason': 'Document contains at least one immense term in field=\"content.keyword\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: \\'[74, 65, 78, 85, 65, 82, 89, 83, 84, 69, 73, 78, 32, 65, 85, 84, 79, 77, 65, 84, 73, 79, 78, 32, 71, 77, 66, 72, 32, 38]...\\', original message: bytes can be at most 32766 in length; got 37003',\n",
       "     'caused_by': {'type': 'max_bytes_length_exceeded_exception',\n",
       "      'reason': 'bytes can be at most 32766 in length; got 37003'}}}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '63',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 188,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '74',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 189,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '75',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 190,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '77',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 191,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '8',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 192,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '84',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 193,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '86',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 194,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}},\n",
       "  {'index': {'_index': 'esg_report_1',\n",
       "    '_type': '_doc',\n",
       "    '_id': '9',\n",
       "    '_version': 1,\n",
       "    'result': 'created',\n",
       "    '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       "    '_seq_no': 195,\n",
       "    '_primary_term': 1,\n",
       "    'status': 201}}]}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------- Feed JSON File to ES - Bulk Upload!!! ----------------------\n",
    "es_client.bulk(body=\"\\n\".join(action_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89e63de8770f628c77675a9211c73c50d8048a4fbbbf8de889960f40f43afefe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
